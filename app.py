import streamlit as st
import google.generativeai as genai
import PyPDF2
from docx import Document
import os

# ==========================================
# [ì„ ìƒë‹˜ ë¹„ë°€ ì„¤ì • êµ¬ì—­]
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    st.error("ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    st.stop()
# ==========================================

# 1. í™”ë©´ ì„¤ì •
st.set_page_config(page_title="4.ìš°ë¦¬ ëª¸ì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥", page_icon="ğŸ©º")
st.title("4.ìš°ë¦¬ ëª¸ì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥")
st.caption("ì„ ìƒë‹˜ê³¼ í•¨ê»˜ ìš°ë¦¬ ëª¸ì— ëŒ€í•´ ì¬ë¯¸ìˆê²Œ ì•Œì•„ë³´ì•„ìš”!")

# 2. ìë£Œ ìë™ ì½ê¸° í•¨ìˆ˜
@st.cache_data(show_spinner=False)
def load_data_from_folder():
    folder_path = 'data'
    combined_text = ""
    
    if not os.path.exists(folder_path):
        return None

    files = os.listdir(folder_path)
    if not files:
        return None

    KEYWORDS = [
        "ë¼ˆ", "ê·¼ìœ¡", "ì†Œí™”", "ì…", "ì‹ë„", "ìœ„", "ì°½ì", "í•­ë¬¸", "ì˜ì–‘ì†Œ",
        "í˜¸í¡", "ìˆ¨", "í", "í—ˆíŒŒ", "ì‚°ì†Œ", "ì´ì‚°í™” íƒ„ì†Œ",
        "ìˆœí™˜", "ì‹¬ì¥", "í˜ˆê´€", "í˜ˆì•¡", "ë§¥ë°•",
        "ë°°ì„¤", "ì½©íŒ¥", "ì˜¤ì¤Œ", "ë°©ê´‘", "ë…¸íë¬¼",
        "ìê·¹", "ë°˜ì‘", "ì‹ ê²½", "ë‡Œ", "ì²™ìˆ˜", "ê°ê°"
    ]

    for filename in files:
        file_path = os.path.join(folder_path, filename)
        try:
            if filename.endswith('.pdf'):
                with open(file_path, 'rb') as f:
                    pdf_reader = PyPDF2.PdfReader(f)
                    for page in pdf_reader.pages:
                        text = page.extract_text()
                        if text and any(keyword in text for keyword in KEYWORDS):
                            combined_text += f"\n\n--- [ì°¸ê³  ìë£Œ: {filename}] ---\n{text}"
            elif filename.endswith('.docx'):
                doc = Document(file_path)
                for para in doc.paragraphs:
                    text = para.text
                    if any(keyword in text for keyword in KEYWORDS):
                         combined_text += text + "\n"
            elif filename.endswith('.txt'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                    combined_text += text
        except Exception:
            pass 

    if len(combined_text) > 50000:
        combined_text = combined_text[:50000]
        combined_text += "\n...(ë‚´ìš©ì´ ë§ì•„ ìš”ì•½ë¨)..."
        
    return combined_text

# 3. ëª¨ë¸ ìë™ ê²€ìƒ‰ ë° ì—°ê²° (ì™„ì „ ìˆ˜ì •ë¨ â­)
if not GOOGLE_API_KEY:
    st.error("ğŸš¨ ì„ ìƒë‹˜! ì½”ë“œ ìœ—ë¶€ë¶„ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# (ì´ ë¶€ë¶„ì´ í•µì‹¬! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì§ì ‘ ì°¾ìŠµë‹ˆë‹¤)
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    
    found_model_name = None
    
    # 1. í˜„ì¬ ê³„ì •ì—ì„œ ì“¸ ìˆ˜ ìˆëŠ” ëª¨ë“  ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    for m in genai.list_models():
        # ëŒ€í™”(generateContent)ê°€ ê°€ëŠ¥í•œ ëª¨ë¸ì¸ì§€ í™•ì¸
        if 'generateContent' in m.supported_generation_methods:
            # ìš°ì„ ìˆœìœ„: flash -> pro -> ê·¸ëƒ¥ gemini ìˆœì„œë¡œ ì°¾ê¸°
            if 'gemini-1.5-flash' in m.name:
                found_model_name = m.name
                break # ì°¾ìœ¼ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
            elif 'gemini-1.5-pro' in m.name and found_model_name is None:
                found_model_name = m.name
            elif 'gemini-pro' in m.name and found_model_name is None:
                found_model_name = m.name
    
    # ë§Œì•½ ìœ„ì˜ ì¡°ê±´ì— ë§ëŠ” ê²Œ ì—†ìœ¼ë©´, ëª©ë¡ì˜ ì²« ë²ˆì§¸ ê²ƒì„ ê·¸ëƒ¥ ì”ë‹ˆë‹¤.
    if found_model_name is None:
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if all_models:
            found_model_name = all_models[0]
        else:
            st.error("ğŸ˜­ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

    # ì°¾ì€ ëª¨ë¸ë¡œ ì—°ê²°!
    model = genai.GenerativeModel(found_model_name)
    st.sidebar.success(f"âœ… ìë™ ì—°ê²°ë¨: {found_model_name}")

    # ìë£Œ ì½ê¸° ì‹œì‘
    if "local_knowledge" not in st.session_state:
        with st.spinner("ì„ ìƒë‹˜ì´ ìë£Œë¥¼ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”... ì ì‹œë§Œìš”! ğŸ“š"):
            data = load_data_from_folder()
            if data:
                st.session_state.local_knowledge = data
            else:
                st.session_state.local_knowledge = ""
                st.warning("âš ï¸ 'data' í´ë”ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì—†ì–´ìš”. ì±—ë´‡ì´ ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œë§Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.")

except Exception as e:
    st.error(f"ëª¨ë¸ ì—°ê²° ì˜¤ë¥˜: {e}\n\n(API í‚¤ê°€ ì •í™•í•œì§€, ì¸í„°ë„·ì´ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.)")
    st.stop()

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìœ¤ë¦¬ ê·œì • í¬í•¨)
system_prompt = f"""
ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ 6í•™ë…„ ê³¼í•™ ì„ ìƒë‹˜(ì´ëª¨ì§€: ğŸ§‘â€ğŸ«)ì…ë‹ˆë‹¤.
ì•„ë˜ [í•™ìŠµ ìë£Œ]ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìƒê³¼ ëŒ€í™”í•©ë‹ˆë‹¤.

[í•™ìŠµ ìë£Œ]:
{st.session_state.local_knowledge}

[âš ï¸ ì¤‘ìš”: ìœ¤ë¦¬ ë° ì•ˆì „ ê°€ì´ë“œë¼ì¸]:
1. **ë¹„ì†ì–´ ë° ë¹„ë°© ê¸ˆì§€**: í•™ìƒì´ ìš•ì„¤, ë¹„ì†ì–´, ì¹œêµ¬ë¥¼ ë†€ë¦¬ëŠ” ë§ì„ ì“°ë©´ ì •ì¤‘í•˜ì§€ë§Œ ë‹¨í˜¸í•˜ê²Œ ë‹µë³€ì„ ê±°ì ˆí•˜ê³  ë°”ë¥¸ ë§ì„ ì“°ë„ë¡ ì§€ë„í•˜ì„¸ìš”.
2. **ìœ„í—˜í•œ ì§ˆë¬¸ ì°¨ë‹¨**: í­ë°œë¬¼ ì œì¡°, ìí•´, í­ë ¥, ì•½ë¬¼ ì˜¤ë‚¨ìš© ë“± ìœ„í—˜í•˜ê±°ë‚˜ ë¹„ìœ¤ë¦¬ì ì¸ ì§ˆë¬¸ì—ëŠ” **ì ˆëŒ€ ë‹µí•˜ì§€ ë§ˆì„¸ìš”.**
3. **ëŒ€ì²˜ ë°©ë²•**: "ê·¸ëŸ° ìœ„í—˜í•œ í–‰ë™ì€ í•˜ë©´ ì•ˆ ë¼.", "ìš°ë¦¬ ê³¼í•™ ìˆ˜ì—…ê³¼ ê´€ë ¨ ì—†ëŠ” ë¹„ìœ¤ë¦¬ì ì¸ ë‚´ìš©ì€ ì•Œë ¤ì¤„ ìˆ˜ ì—†ì–´."ë¼ê³  ë§í•˜ê³ , ë‹¤ì‹œ ìš°ë¦¬ ëª¸ì— ëŒ€í•œ í•™ìŠµ ì£¼ì œë¡œ ëŒ€í™”ë¥¼ ìœ ë„í•˜ì„¸ìš”.
4. **ê°œì¸ì •ë³´ ë³´í˜¸**: í•™ìƒì´ ë³¸ì¸ì˜ ì´ë¦„, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ë¥¼ ë§í•˜ë ¤ í•˜ë©´ "ê°œì¸ì •ë³´ëŠ” ì†Œì¤‘í•˜ë‹ˆê¹Œ ì—¬ê¸°ì— ì ìœ¼ë©´ ì•ˆ ë¼!"ë¼ê³  ì•Œë ¤ì£¼ì„¸ìš”.

[ëŒ€í™” ë° í–‰ë™ ìˆ˜ì¹™]:
1. **ë§íˆ¬**: ë‹¤ì •í•˜ê³  ì¹œì ˆí•œ ì¡´ëŒ“ë§(í•´ìš”ì²´) ì‚¬ìš©. ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©.
2. **ì„¤ëª…**: ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì´ì•¼ê¸°í•˜ë“¯ ì„¤ëª…(ë¹„ê³„ ì„¤ì •). ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë§Œ í•˜ì§€ ë§ê³  ì›ë¦¬ë¥¼ ì„¤ëª…í•  ê²ƒ.
3. **ì˜¤ê°œë… êµì •**: í•™ìƒì´ í‹€ë¦¬ë©´ ë°˜ë¡€ë¥¼ ë“¤ì–´ ìŠ¤ìŠ¤ë¡œ ê¹¨ë‹«ê²Œ ìœ ë„. ì ˆëŒ€ ê·¸ëƒ¥ ë„˜ì–´ê°€ì§€ ë§ ê²ƒ.
4. **ì¶œì²˜ ì–¸ê¸‰ ê¸ˆì§€**: "ìë£Œì— ë”°ë¥´ë©´" ê°™ì€ ë§ ê¸ˆì§€.
5. **ì§ˆë¬¸**: í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì—¬ ì‚¬ê³  í™•ì¥ ìœ ë„.
"""

# 5. ëŒ€í™” ì²˜ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•! ë°˜ê°€ì›Œ. ì„ ìƒë‹˜ì´ë‘ ìš°ë¦¬ ëª¸ì— ëŒ€í•´ ì¬ë¯¸ìˆê²Œ ì´ì•¼ê¸° ë‚˜ëˆ ë³¼ê¹Œ? í˜¹ì‹œ ê¶ê¸ˆí•œ ê³¼í•™ ì´ì•¼ê¸°ê°€ ìˆë‹ˆ? ğŸ˜Š"}
    ]

for message in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ«" if message["role"] == "assistant" else "ğŸ§‘â€ğŸ“"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì´ë‚˜ ëŒ€ë‹µì„ ì…ë ¥í•˜ì„¸ìš”"):
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ“"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ğŸ§‘â€ğŸ«"):
        msg_box = st.empty()
        try:
            # í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì ì…ë ¥ì„ í•©ì³ì„œ ë³´ëƒ„
            full_prompt = system_prompt + f"\n\ní•™ìƒ ë§: {prompt}"
            response = model.generate_content(full_prompt, stream=True)
            full_response = ""
            for chunk in response:
                full_response += chunk.text
                msg_box.markdown(full_response + "â–Œ")
            msg_box.markdown(full_response)
            st.session_state.messages.append({"role": "model", "content": full_response})     
        except Exception as e:
            # ì˜¤ë¥˜ê°€ ë‚˜ë©´ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì•Œë¦¼
            st.error(f"ë‹µë³€ì„ ë§Œë“œëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”: {e}")